---
tags:
  - type/permanent
  - attr/concept
  - cs/llm
  - ml/fine-tuning
---

# PEFT - 参数高效微调 (Parameter-Efficient Fine-Tuning)

## 定义
一类微调方法的总称，通过冻结原始模型权重并引入少量可训练参数，实现高效的模型适配。核心思想：**少量新参数 + 冻结原权重 = 快速适配**。

## 核心特征
- **参数占比**：通常 0.5% ~ 3%
- **计算高效**：显存占用少，训练速度快
- **灵活模块化**：多个任务可共享基础模型，叠加不同 PEFT 模块

## 主要方法

### 低秩适配类
- [[LoRA]] - 最常用，添加低秩矩阵
- [[OFT]] - 正交约束，数值更稳定
- QLoRA - [[LoRA]] + 量化

### 前缀微调类
- Prefix-Tuning - 在 embedding 前添加可训练向量
- Prompt-Tuning - 简化的 Prefix-Tuning
- P-Tuning - 改进的 Prompt-Tuning

### 适配器类
- Adapter - 在 MLP 层旁添加小型神经网络
- AdapterFusion - 多适配器融合

## 与 [[SFT]] 的对比

| 特性 | SFT | PEFT |
|------|-----|------|
| 参数更新率 | 100% | 0.5~3% |
| 显存占用 | 高 | 低 |
| 训练速度 | 慢 | 快（5-10 倍） |
| 灾难性遗忘 | 风险大 | 风险小 |
| 模块化程度 | 低 | 高 |
| 性能天花板 | 最高 | 中等 |

## 使用场景
- 显存有限（<16GB）
- 快速迭代原型
- 多任务场景（每任务一个适配器）
- 资源受限的边端设备

## 与其他方法的关系
- [[LoRA]] 和 [[OFT]] 都是 PEFT 的具体实现
- 可与 [[参数冻结策略]] 结合
- 是 [[DPO]] 和 [[KTO]] 的常用基础

## 注记
PEFT 已成为开源社区微调的标准做法，LLaMA-Factory、Axolotl 等框架都原生支持。
