---
tags:
  - type/permanent
  - attr/technique
  - cs/llm
  - ml/peft
---

# OFT - 正交微调 (Orthogonal Finetuning)

## 定义
一种 [[PEFT|参数高效方法]]，通过学习正交变换矩阵对权重进行微调。与 [[LoRA]] 不同，OFT 在**权重矩阵的行空间**上施加正交约束，保证变换的数值稳定性和几何意义。

## 核心原理
原权重 $W$ 经正交变换 $Q$ 映射：
$$W' = W \cdot Q, \quad Q^T Q = I$$

其中 $Q$ 的学习参数远少于 $W$。

## 与 [[SFT]] 和 [[LoRA]] 的对比

| 特性 | SFT | LoRA | OFT |
|------|-----|------|-----|
| 参数量 | 100% | 0.5~3% | 1~2% |
| 可训练参数类型 | 全部权重 | 低秩适配 | 正交变换 |
| 几何约束 | 无 | 秩约束 | 正交约束 |
| 数值稳定性 | 中等 | 中等 | 高 |
| 计算复杂度 | 高 | 低 | 中低 |

## 关键优点
- **数值稳定性高**：正交约束保证不改变权重的模长
- **参数高效**：仅 1~2% 的参数，比 [[LoRA]] 更紧凑
- **适合微调微调**：在已微调模型上再次微调时稳定性更好

## 与其他方法的关系
- 比 [[LoRA]] 约束更强（正交 vs 秩约束）
- 比 [[SFT]] 参数少 100 倍
- 可与 [[参数冻结策略]] 结合使用

## 适用场景
- 对齐敏感任务（正交约束减少灾难性遗忘）
- 多层次微调场景（fine-tuning the fine-tuning）
- 追求极致参数效率

## 注记
OFT 的梯度计算略复杂，部分框架支持有限。超参调优空间相比 [[LoRA]] 小。
