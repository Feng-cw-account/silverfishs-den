---
tags:
  - type/permanent
  - attr/technique
  - cs/llm
  - ml/rl-alignment
---

# KTO - 卡尼曼-特维斯基优化 (Kahneman-Tversky Optimization)

## 定义
一种基于行为经济学理论的偏好优化方法。利用人类决策中的"损失厌恶"与"参考点依赖"特性，直接优化模型使其更符合人类偏好。

## 核心特性
- **理论基础**：前景理论（Prospect Theory），而非信息论
- **数据形式**：单独反应 `(prompt, response, 好/坏)`，而非成对比较
- **权重机制**：自适应权重 $w_+, w_-$ 反映损失厌恶效应

## 数学原理
KTO 为每个样本 $(x, y)$ 和标签 $z$（好/坏）优化：
$$\mathcal{L}_{KTO} = \mathbb{E}_{z=1}\left[w_+ \cdot \ell(v(x,y))\right] + \mathbb{E}_{z=0}\left[w_- \cdot \ell(-v(x,y))\right]$$

其中 $w_+, w_-$ 是从人类数据推导的权重，反映损失厌恶系数。

## 与 [[DPO]] 的详细对比

| 特性 | DPO | KTO |
|------|-----|-----|
| 理论基础 | 信息论（Bradley-Terry） | 行为经济学（前景理论） |
| 损失函数 | 对数概率比 | 加权偏好损失 |
| 数据形式 | 偏好对 $(y_w, y_l)$ | 单独反应 (prompt, response, 好/坏) |
| 灵活性 | 中等 | 高（可独立评价） |
| 效率 | 中等 | 通常更高效 |
| 不平衡数据处理 | 一般 | 优秀 |

## 关键优点
- **处理不平衡数据**：好样本与坏样本数量差异大时更稳定
- **多样性偏好**：用户对好/坏的定义差异大时更灵活
- **实时反馈**：可增量更新单个样本标签
- **参考点机制**：模拟人类的"损失厌恶"心理

## 数据格式
```json
{
  "prompt": "...",
  "response": "...",
  "is_good": true/false
}
```

## 应用场景
- 数据严重不平衡（如 80% 好样本，20% 坏样本）
- 用户偏好多元化且难以配对
- 需要在线/增量学习
- 现实标注场景（单独评价比配对评价更自然）

## 与其他方法的关系
- 改进于 [[DPO]]（用行为经济学替代信息论）
- 与 [[SFT]] 结合效果好
- 可与 [[LoRA]] 或 [[OFT]] 协同

## 注记
KTO 是较新的方法（2024 年提出），理论上改进 [[DPO]]，实践中在不平衡数据上表现更佳。值得关注。
